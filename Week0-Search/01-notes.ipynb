{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a7e66f",
   "metadata": {},
   "source": [
    "# CS50 AI - Search Algorithms Study Notes\n",
    "\n",
    "## Course Overview\n",
    "**CS50's Introduction to Artificial Intelligence with Python**\n",
    "- Instructors: Brian Yu (brian@cs.harvard.edu), David J. Malan (malan@harvard.edu)\n",
    "- Platform: OpenCourseWare\n",
    "\n",
    "## What is Artificial Intelligence?\n",
    "\n",
    "AI covers techniques that appear as sentient behavior by computers, including:\n",
    "- Face recognition in social media photos\n",
    "- Chess champions (beating world champions)\n",
    "- Speech processing (Siri, Alexa)\n",
    "\n",
    "## Core AI Topics Covered\n",
    "\n",
    "### 1. **Search** ðŸ”\n",
    "Finding solutions to problems (navigation apps, game moves)\n",
    "\n",
    "### 2. **Knowledge** ðŸ§ \n",
    "Representing information and drawing inferences\n",
    "\n",
    "### 3. **Uncertainty** ðŸŽ²\n",
    "Dealing with uncertain events using probability\n",
    "\n",
    "### 4. **Optimization** âš¡\n",
    "Finding not just correct solutions, but the best solutions\n",
    "\n",
    "### 5. **Learning** ðŸ“ˆ\n",
    "Improving performance based on data and experience\n",
    "\n",
    "### 6. **Neural Networks** ðŸ§¬\n",
    "Brain-inspired program structures for effective task performance\n",
    "\n",
    "### 7. **Language** ðŸ’¬\n",
    "Processing natural human language\n",
    "\n",
    "---\n",
    "\n",
    "## Search Problems - Core Concepts\n",
    "\n",
    "### Key Terminology\n",
    "\n",
    "**Agent** ðŸ¤–\n",
    "- Entity that perceives environment and acts upon it\n",
    "- Example: Car representation in navigation app\n",
    "\n",
    "**State** ðŸ“\n",
    "- Configuration of agent in its environment\n",
    "- Example: Any arrangement of numbers in 15-puzzle\n",
    "\n",
    "**Initial State** ðŸš€\n",
    "- Starting point for search algorithm\n",
    "- Example: Current location in navigation\n",
    "\n",
    "**Actions** âš™ï¸\n",
    "- Choices available in a state\n",
    "- Function: `Actions(s)` â†’ set of possible actions in state s\n",
    "- Example: In 15-puzzle, ways to slide squares (2-4 options depending on empty square position)\n",
    "\n",
    "**Transition Model** ðŸ”„\n",
    "- Description of resulting state from performing action\n",
    "- Function: `Results(s, a)` â†’ new state from action a in state s\n",
    "\n",
    "**State Space** ðŸŒ\n",
    "- Set of all reachable states from initial state\n",
    "- Visualized as directed graph (nodes = states, arrows = actions)\n",
    "- Example: 15-puzzle has 16!/2 possible configurations\n",
    "\n",
    "**Goal Test** ðŸŽ¯\n",
    "- Condition determining if state is goal state\n",
    "- Example: \"Are we at destination?\" for navigation\n",
    "\n",
    "**Path Cost** ðŸ’°\n",
    "- Numerical cost associated with a path\n",
    "- Example: Navigation apps minimize time/distance\n",
    "\n",
    "### Solution Types\n",
    "\n",
    "**Solution** âœ…\n",
    "- Sequence of actions from initial â†’ goal state\n",
    "\n",
    "**Optimal Solution** ðŸ†\n",
    "- Solution with lowest path cost among all solutions\n",
    "\n",
    "---\n",
    "\n",
    "## Search Data Structures\n",
    "\n",
    "### Node Structure ðŸ“¦\n",
    "Contains:\n",
    "- **State**: Current configuration\n",
    "- **Parent**: Node that generated this node\n",
    "- **Action**: Action applied to parent to reach this node\n",
    "- **Path Cost**: Total cost from initial state to this node\n",
    "\n",
    "### Frontier Mechanism ðŸšª\n",
    "Manages nodes during search:\n",
    "\n",
    "```\n",
    "Repeat:\n",
    "1. If frontier is empty â†’ No solution exists\n",
    "2. Remove a node from frontier\n",
    "3. If node contains goal state â†’ Return solution\n",
    "4. Else:\n",
    "   - Expand node (find reachable nodes)\n",
    "   - Add new nodes to frontier\n",
    "   - Add current node to explored set\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Search Algorithms\n",
    "\n",
    "### 1. Depth-First Search (DFS) ðŸ“Š\n",
    "\n",
    "**Strategy**: Go as deep as possible in one direction before trying others\n",
    "**Data Structure**: Stack (Last-In-First-Out)\n",
    "\n",
    "**Pros** âœ…\n",
    "- Fastest at best case (if lucky with path choice)\n",
    "- Memory efficient\n",
    "\n",
    "**Cons** âŒ\n",
    "- May not find optimal solution\n",
    "- Worst case: explores every possible path\n",
    "\n",
    "**Code Example**:\n",
    "```python\n",
    "def remove(self):\n",
    "    if self.empty():\n",
    "        raise Exception(\"empty frontier\")\n",
    "    else:\n",
    "        # Remove last item (newest node)\n",
    "        node = self.frontier[-1]\n",
    "        self.frontier = self.frontier[:-1]\n",
    "        return node\n",
    "```\n",
    "\n",
    "**Real-world analogy**: Searching for keys by completely emptying one pants pocket before moving to the next pocket.\n",
    "\n",
    "### 2. Breadth-First Search (BFS) ðŸ“ˆ\n",
    "\n",
    "**Strategy**: Take one step in each direction before taking second step in any direction\n",
    "**Data Structure**: Queue (First-In-First-Out)\n",
    "\n",
    "**Pros** âœ…\n",
    "- **Guaranteed to find optimal solution**\n",
    "- Systematic exploration\n",
    "\n",
    "**Cons** âŒ\n",
    "- Almost always takes longer than minimum time\n",
    "- Higher memory usage\n",
    "\n",
    "**Code Example**:\n",
    "```python\n",
    "def remove(self):\n",
    "    if self.empty():\n",
    "        raise Exception(\"empty frontier\")\n",
    "    else:\n",
    "        # Remove first item (oldest node)\n",
    "        node = self.frontier[0]\n",
    "        self.frontier = self.frontier[1:]\n",
    "        return node\n",
    "```\n",
    "\n",
    "**Real-world analogy**: Searching for keys by checking one pocket in pants, one drawer, one table spot, etc., before going back for second pocket.\n",
    "\n",
    "### 3. Greedy Best-First Search ðŸŽ¯\n",
    "\n",
    "**Strategy**: Expand node closest to goal using heuristic function h(n)\n",
    "**Type**: Informed search algorithm\n",
    "\n",
    "**Key Concept**: Uses additional knowledge about the problem\n",
    "**Example Heuristic**: Manhattan distance in maze (ignores walls, counts steps up/down/sideways)\n",
    "\n",
    "**Important**: Heuristic can be wrong and lead to suboptimal paths\n",
    "\n",
    "![Fig1()](./01.png)\n",
    "![Fig2()](./02.png)\n",
    "\n",
    "\n",
    "### 4. A* Search â­\n",
    "\n",
    "**Strategy**: Considers both:\n",
    "- **g(n)**: Cost accrued until current location\n",
    "- **h(n)**: Estimated cost from current location to goal\n",
    "\n",
    "**Formula**: f(n) = g(n) + h(n)\n",
    "\n",
    "**Advantage**: More accurate cost determination, prevents going down inefficient paths\n",
    "\n",
    "**Requirements for Optimality**:\n",
    "- **Admissible**: h(n) never overestimates true cost\n",
    "- **Consistent**: h(n) â‰¤ h(n') + c for successor node n' with step cost c\n",
    "\n",
    "![Fig3()](./03.png)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Adversarial Search ðŸŽ®\n",
    "\n",
    "### Game Context\n",
    "- Algorithm faces opponent trying to achieve opposite goal\n",
    "- Common in games like Tic-Tac-Toe, Chess\n",
    "\n",
    "### Minimax Algorithm ðŸŽ²\n",
    "\n",
    "**Core Concept**: \n",
    "- Winning conditions: (-1) for one side, (+1) for other side\n",
    "- Minimizing player: tries to get lowest score\n",
    "- Maximizing player: tries to get highest score\n",
    "\n",
    "**Tic-Tac-Toe Implementation**:\n",
    "\n",
    "**Functions**:\n",
    "- `Sâ‚€`: Initial state (empty 3Ã—3 board)\n",
    "- `Players(s)`: Returns whose turn it is (X or O)\n",
    "- `Actions(s)`: Returns legal moves (free spots)\n",
    "- `Result(s, a)`: Returns new state after action a\n",
    "- `Terminal(s)`: Checks if game ended (win/tie)\n",
    "- `Utility(s)`: Returns utility value (-1, 0, +1)\n",
    "\n",
    "**Algorithm Process**:\n",
    "```\n",
    "Function Max-Value(state):\n",
    "    v = -âˆž\n",
    "    if Terminal(state):\n",
    "        return Utility(state)\n",
    "    for action in Actions(state):\n",
    "        v = Max(v, Min-Value(Result(state, action)))\n",
    "    return v\n",
    "\n",
    "Function Min-Value(state):\n",
    "    v = âˆž\n",
    "    if Terminal(state):\n",
    "        return Utility(state)\n",
    "    for action in Actions(state):\n",
    "        v = Min(v, Max-Value(Result(state, action)))\n",
    "    return v\n",
    "```\n",
    "\n",
    "![Fig4()](./04-1.png)\n",
    "![Fig4-2()](./04-2.png)\n",
    "![Fig5()](./05.png)\n",
    "\n",
    "\n",
    "\n",
    "### Alpha-Beta Pruning âœ‚ï¸\n",
    "\n",
    "**Optimization**: Skips unfavorable recursive computations\n",
    "\n",
    "**Logic**: If evidence shows an action will be worse than established option, stop exploring that branch\n",
    "\n",
    "**Example**: \n",
    "- Maximizer has action valued at 4\n",
    "- Next action shows minimizer can get 3\n",
    "- No need to compute other minimizer options (will choose â‰¤3, which is worse than 4)\n",
    "\n",
    "### Depth-Limited Minimax â±ï¸\n",
    "\n",
    "**Problem**: \n",
    "- Tic-Tac-Toe: 255,168 possible games âœ… (manageable)\n",
    "- Chess: 10Â²â¹â°â°â° possible games âŒ (impossible to compute)\n",
    "\n",
    "**Solution**: \n",
    "- Stop after pre-defined number of moves\n",
    "- Use **evaluation function** to estimate utility of non-terminal states\n",
    "- Example: Chess evaluation based on piece values and positions\n",
    "\n",
    "![Fig6()](./06.png)\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways ðŸŽ“\n",
    "\n",
    "1. **Search Problems**: Foundation of AI problem-solving\n",
    "2. **Algorithm Choice Matters**: \n",
    "   - DFS: Fast but potentially suboptimal\n",
    "   - BFS: Optimal but slower\n",
    "   - A*: Best balance with good heuristic\n",
    "3. **Informed > Uninformed**: Knowledge about problem improves performance\n",
    "4. **Adversarial Search**: Different approach for competitive scenarios\n",
    "5. **Practical Limitations**: Real-world constraints require optimizations (pruning, depth limits)\n",
    "\n",
    "---\n",
    "\n",
    "## Study Questions ðŸ¤”\n",
    "\n",
    "1. When would you choose DFS over BFS?\n",
    "2. What makes a heuristic function admissible?\n",
    "3. How does Alpha-Beta pruning improve Minimax efficiency?\n",
    "4. Why is A* often preferred over Greedy Best-First Search?\n",
    "5. What are the trade-offs in Depth-Limited Minimax?\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps ðŸ“š\n",
    "- Implement search algorithms in Python\n",
    "- Experiment with different heuristics\n",
    "- Practice with puzzle problems (15-puzzle, 8-queens)\n",
    "- Explore game AI implementations"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
